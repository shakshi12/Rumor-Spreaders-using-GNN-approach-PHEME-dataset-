{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "colab_type": "code",
    "id": "fgVJT7PRV0UR",
    "outputId": "f72348fb-119c-4367-e118-f3af7c9b16ba"
   },
   "outputs": [],
   "source": [
    "!sudo apt install graphviz libgraphviz-dev libcgraph6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 978
    },
    "colab_type": "code",
    "id": "3vRQG-yaV3Qz",
    "outputId": "84eb7446-e2d2-4c00-b71f-2e64835a6fdc"
   },
   "outputs": [],
   "source": [
    "!pip install spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "uAXc1JypWGlj",
    "outputId": "a40dd1b3-37a0-4423-c819-a9c57bc0b56d"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/danielegrattarola/spektral.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DtHvfsmXWQ68",
    "outputId": "9d0f6829-d721-46b9-fefe-fa622302e3ca"
   },
   "outputs": [],
   "source": [
    "cd spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fhvT_HvbWTil",
    "outputId": "c26668de-ae0f-446f-9bfe-b77aacfef9d1"
   },
   "outputs": [],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "5_Ruy5uKeEth",
    "outputId": "b7acecd4-b326-488c-dc63-dc124c33f65b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiKS7cpuYUm2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/content/drive/My Drive/features_user_imp_added_german.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/features_user_imp_added_german.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.target_variables == 0].count()['target_variables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.target_variables == 1].count()['target_variables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DwSP8eDVhjJU"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "id": "Eu3I3gCgdYV4",
    "outputId": "114b0225-b0b2-44f3-f1c3-c316cb5c6238"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4XIT3ZPbTs3"
   },
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6U0fqCsZbTs6",
    "outputId": "b350e1f7-3b31-4886-9c62-73ee8571ea94"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X6R0aYNUufNB",
    "outputId": "52f16740-9f32-4fc1-ed11-c56ac08b2a72"
   },
   "outputs": [],
   "source": [
    "df.target_variables.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3pZCHeCbTs9"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values #Take all the columns except last one\n",
    "y = df.iloc[:, -1].values #Take the last column as the result\n",
    "from scipy import sparse\n",
    "#X_csr = sparse.csr_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iefK_CgSbTs_",
    "outputId": "92d4fff6-1fcc-4203-c20f-81dbfecb2d1a"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUxE1X_DbTtI"
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7y0EpO_ebTtK",
    "outputId": "d8a5b05d-5eb0-4fed-b1ce-42f237d9f9d7"
   },
   "outputs": [],
   "source": [
    "G = nx.read_multiline_adjlist(\"/content/drive/My Drive/test_german.adjlist\")\n",
    "A = nx.adjacency_matrix(G)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKIh3Q9JbTtP"
   },
   "outputs": [],
   "source": [
    "n1 = df['target_variables']\n",
    "classes = 2\n",
    "y = np.zeros((len(df),classes))\n",
    "#labels\n",
    "n = list(n1)\n",
    "for i in range(len(df)):\n",
    "    if (n[i] == 1):\n",
    "        y[i,1] = 1\n",
    "    elif (n[i] == 0):\n",
    "        y[i,0] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blZo1aT8bTtR"
   },
   "outputs": [],
   "source": [
    "N = A.shape[0]\n",
    "F = X.shape[-1]\n",
    "n_classes = y.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k408JMXXgNOt",
    "outputId": "518a3590-55d9-46c0-c121-69dcf194650f"
   },
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DBwFHQirg4S0",
    "outputId": "224872ae-8dc4-44f7-bf0d-f06a7257fa83"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsZSQiXaamMT"
   },
   "outputs": [],
   "source": [
    "from spektral.layers import GraphConv\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "#import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWacBW8BleXY"
   },
   "outputs": [],
   "source": [
    "y1 = df['target_variables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8DRnaRgql6el"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcUDGRPcAe2s"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-OAHWAcdo6O"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from spektral.datasets import citation\n",
    "from spektral.layers import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zy0BXnXudtgP"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "channels = 32           # Number of channels in the first layer\n",
    "#N = X.shape[0]          # Number of nodes in the graph\n",
    "#F = X.shape[1]          # Original size of node features\n",
    "#n_classes = y.shape[1]  # Number of classes\n",
    "dropout = 0.5           # Dropout rate for the features\n",
    "l2_reg = 5e-4 / 2       # L2 regularization rate\n",
    "learning_rate = 1e-2    # Learning rate\n",
    "epochs = 300            # Number of training epochs\n",
    "es_patience = 10        # Patience for early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "9F6xZdFod1OR",
    "outputId": "856d09d6-8856-4fc5-c301-ebac7250c1fa"
   },
   "outputs": [],
   "source": [
    "# Preprocessing operations\n",
    "fltr = GraphConv.preprocess(A).astype('f4')\n",
    "#X = X.toarray()\n",
    "# Model definition\n",
    "X_in = Input(shape=(F, ))\n",
    "fltr_in = Input((N, ), sparse=True)\n",
    "\n",
    "\n",
    "dropout_1 = Dropout(dropout)(X_in)\n",
    "graph_conv_1 = GraphConv(channels,\n",
    "                        activation='relu',\n",
    "                        kernel_regularizer=l2(l2_reg),\n",
    "                        use_bias=False)([dropout_1, fltr_in])\n",
    "dropout_2 = Dropout(dropout)(graph_conv_1)\n",
    "graph_conv_2 = GraphConv(n_classes,\n",
    "                        activation='sigmoid',\n",
    "                        use_bias=False)([dropout_2, fltr_in])\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, fltr_in], outputs=graph_conv_2)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              weighted_metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5CRSgPebbTtZ",
    "outputId": "0561d585-f0f4-4797-bfd3-bcb8de877384"
   },
   "outputs": [],
   "source": [
    "# define 5-fold cross validation test harness\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "tp = []\n",
    "tn = []\n",
    "fp = []\n",
    "fn = []\n",
    "\n",
    "metrics_acc = []\n",
    "metrics_precision = []\n",
    "metrics_recall = []\n",
    "metrics_f1 = []\n",
    "pmacro = []\n",
    "pmicro = []\n",
    "pbinary = []\n",
    "rmacro = []\n",
    "rmicro = []\n",
    "rbi = []\n",
    "a = []\n",
    "f = []\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for k, (train, test) in enumerate(kfold.split(X, y1)):\n",
    "  \n",
    "    #plotter = tfdocs.plots.HistoryPlotter(metric = 'binary_crossentropy', smoothing_std=10)\n",
    "    #regularizer_histories = {}\n",
    "    print(\"k : \", k)\n",
    "  #standardize\n",
    "    sc_X = StandardScaler() \n",
    "    X[train] = sc_X.fit_transform(X[train]) \n",
    "    X[test] = sc_X.transform(X[test])\n",
    "    #X_csr = sparse.csr_matrix(X)\n",
    "    print(\"done scaling\")\n",
    "    \n",
    "    l = []\n",
    "    for i in range(0, len(df)):\n",
    "        l.append(False)\n",
    "    #train indices\n",
    "    train_indices = list(train)    \n",
    "    for i in train_indices:\n",
    "        l[i] = True\n",
    "\n",
    "    print(\"train mask processing: \")\n",
    "    train_mask = np.array(l)\n",
    "\n",
    "    l = []\n",
    "    for i in range(0, len(df)):\n",
    "      l.append(False)\n",
    "     #test indices           \n",
    "    test_indices = list(test)  \n",
    "    for i in test_indices:\n",
    "      l[i] = True\n",
    "    print(\"test mask processing: \")\n",
    "    test_mask = np.array(l)\n",
    "    \n",
    "    #validation indices (taken at random)\n",
    "    val = np.random.choice(2906, 300, replace = False)            \n",
    "    val_indices = list(val)    \n",
    "    l = []\n",
    "    for i in range(0, len(df)):\n",
    "      l.append(False)\n",
    "    for i in val_indices:\n",
    "      l[i] = True\n",
    "    val_mask = np.array(l)\n",
    "    print(\"val mask processing: \")\n",
    "   \n",
    "\n",
    "    # Model definition\n",
    "    #X_in = Input(shape=(F, ))  # Input layer for X\n",
    "    #A_in = Input((N, ), sparse=True)  # Input layer for A\n",
    "\n",
    "    #graph_conv_1 = GraphConv(32, activation='relu')([X_in, A_in])\n",
    "    print(\"graph conv1\")\n",
    "    #dropout = Dropout(0.5)(graph_conv_1)\n",
    "    #graph_conv_2 = GraphConv(n_classes, activation='sigmoid', \n",
    "     #                        kernel_regularizer=regularizers.l2(0.5))([dropout, A_in])\n",
    "\n",
    "    # Build model\n",
    "    #model = Model(inputs=[X_in, A_in], outputs=graph_conv_2)\n",
    "    #from spektral import utils\n",
    "    #A = utils.localpooling_filter(A)\n",
    "    #model.compile(optimizer='adam',\n",
    "     #             loss='binary_crossentropy',\n",
    "      #            weighted_metrics=['acc'])\n",
    "    # Train model\n",
    "    validation_data = ([X, fltr], y, val_mask)\n",
    "    history = model.fit([X, fltr],\n",
    "              y,\n",
    "              sample_weight=train_mask,\n",
    "              epochs=epochs,\n",
    "              batch_size=N,\n",
    "              validation_data=validation_data,\n",
    "              shuffle=False,\n",
    "              callbacks=[\n",
    "              EarlyStopping(patience=es_patience,  restore_best_weights=True)\n",
    "          ])  # Shuffling data means shuffling the whole graph\n",
    "\n",
    "    # Evaluate model\n",
    "    eval_results = model.evaluate([X, fltr],\n",
    "                                  y,\n",
    "                                  sample_weight=test_mask,\n",
    "                                  batch_size=N)\n",
    "    print('Done.\\n'\n",
    "          'Test loss: {}\\n'\n",
    "          'Test accuracy: {}'.format(*eval_results))\n",
    "    \n",
    "    import scipy\n",
    "    A1 = scipy.sparse.csr_matrix.todense(fltr)\n",
    "    A1 = pd.DataFrame(A1)\n",
    "    A1 = A1.loc[test_indices,test_indices]\n",
    "    A2 = sparse.csr_matrix(A1)\n",
    "    #A2.shape\n",
    "  \n",
    "    #google\n",
    "    y_pred = model.predict(\n",
    "        [X[test], A2], batch_size=N, verbose=0, steps=None, callbacks=None, max_queue_size=10,\n",
    "        workers=1, use_multiprocessing=False\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    predict_class = np.argmax(y_pred, axis=1)\n",
    "    y2 = np.zeros((len(test),classes))\n",
    "    for i in range(len(test)):\n",
    "        if (predict_class[i] == 1):\n",
    "            y2[i,1] = 1\n",
    "        elif (predict_class[i] == 0):\n",
    "            y2[i,0] = 1\n",
    "\n",
    "    \n",
    "    fpr, tpr, t = roc_curve(y1[test], predict_class)\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (k, roc_auc))\n",
    "      \n",
    "    '''viz = metrics.plot_roc_curve(history, X[test], y1[test],\n",
    "                             name='ROC fold {}'.format(i),\n",
    "                             alpha=0.3, lw=1, ax=ax)\n",
    "    interp_tpr = interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "    \n",
    "'''\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y[test, i], y2[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y[test].ravel(), y2.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "    lw = 2\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "            label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                  ''.format(roc_auc[\"micro\"]),\n",
    "            color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "  \n",
    "    #print(predict_class)\n",
    "    conf_mat = confusion_matrix(y1[test], predict_class)\n",
    "    \n",
    "    print(conf_mat)\n",
    "    \n",
    "    #Evaluation Measures\n",
    "    TP = np.diag(conf_mat)\n",
    "    print(\"True Positive: \", TP)\n",
    "    FP = np.sum(conf_mat, axis=0) - TP\n",
    "    print(\"False Positive: \", FP)\n",
    "    FN = np.sum(conf_mat, axis=1) - TP\n",
    "    print(\"False Negative\", FN)\n",
    "    num_classes = classes\n",
    "    TN = []\n",
    "    for i in range(num_classes):\n",
    "        temp = np.delete(conf_mat, i, 0)    # delete ith row\n",
    "        temp = np.delete(temp, i, 1)  # delete ith column\n",
    "        TN.append(sum(sum(temp)))\n",
    "    print(\"True negative: \", TN)\n",
    "\n",
    "    acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    \n",
    "    print(\"Accuracy: \", acc)\n",
    "\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    F1 = 2 * ((precision * recall)/(precision + recall))\n",
    "    tp.append(TP)\n",
    "    tn.append(TN)\n",
    "    fp.append(FP)\n",
    "    fn.append(FN)\n",
    "    \n",
    "    \n",
    "    metrics_acc.append(acc)\n",
    "    metrics_precision.append(precision)\n",
    "    metrics_recall.append(recall)\n",
    "    metrics_f1.append(F1)\n",
    "    print (\"F1 measure: \", F1)\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "    #print(predict_class)\n",
    "    conf_mat = confusion_matrix(y1[test], predict_class)\n",
    "    \n",
    "    print(conf_mat)\n",
    "    p = precision_score(y1[test], predict_class, average='binary')\n",
    "    print('Precision binary: %.3f' % p)\n",
    "    pbinary.append(p)\n",
    "    p1 = precision_score(y1[test], predict_class, average='micro')\n",
    "    print('Precision micro: %.3f' % p1)\n",
    "    pmicro.append(p1)\n",
    "    p2 = precision_score(y1[test], predict_class, average='macro')\n",
    "    print('Precision macro: %.3f' % p2)\n",
    "    pmacro.append(p2)\n",
    "    r = recall_score(y1[test], predict_class, average='binary')\n",
    "    print('Recall binary: %.3f' % r)\n",
    "    rbi.append(r)\n",
    "    r1 = recall_score(y1[test], predict_class, average='micro')\n",
    "    print('Recall micro: %.3f' % r1)\n",
    "    rmicro.append(r1)\n",
    "    r2 = recall_score(y1[test], predict_class, average='macro')\n",
    "    print('Recall macro: %.3f' % r2)\n",
    "    rmacro.append(r2)\n",
    "    s = f1_score(y1[test], predict_class, average='binary')\n",
    "    print('F-Measure: %.3f' % s)\n",
    "    f.append(s)\n",
    "\n",
    "    ac = accuracy_score(y1[test], predict_class)\n",
    "    a.append(ac)\n",
    "    #Evaluation Measures\n",
    "    TP = np.diag(conf_mat)\n",
    "    print(\"True Positive: \", TP)\n",
    "    FP = np.sum(conf_mat, axis=0) - TP\n",
    "    print(\"False Positive: \", FP)\n",
    "    FN = np.sum(conf_mat, axis=1) - TP\n",
    "    print(\"False Negative\", FN)\n",
    "    num_classes = classes\n",
    "    TN = []\n",
    "    for i in range(num_classes):\n",
    "        temp = np.delete(conf_mat, i, 0)    # delete ith row\n",
    "        temp = np.delete(temp, i, 1)  # delete ith column\n",
    "        TN.append(sum(sum(temp)))\n",
    "    print(\"True negative: \", TN)\n",
    "\n",
    "    acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    \n",
    "    print(\"Accuracy: \", acc)\n",
    "\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    F1 = 2 * ((precision * recall)/(precision + recall))\n",
    "    tp.append(TP)\n",
    "    tn.append(TN)\n",
    "    fp.append(FP)\n",
    "    fn.append(FN)\n",
    "    \n",
    "    \n",
    "    metrics_acc.append(acc)\n",
    "    metrics_precision.append(precision)\n",
    "    metrics_recall.append(recall)\n",
    "    metrics_f1.append(F1)\n",
    "    print (\"F1 measure: \", F1)\n",
    "\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "        label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fsF-XLhAq4aW",
    "outputId": "4d0f4782-10c8-489a-9aa6-d38aa5e000fd"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "ZTafXCD0C-qa",
    "outputId": "1551aba8-70cf-4724-9879-b9f496d8051a"
   },
   "outputs": [],
   "source": [
    "print(\"precision macro: \", np.array(pmacro).mean())\n",
    "print(\"precision micro: \", np.array(pmicro).mean())\n",
    "print(\"precision binary macro: \", np.array(pbinary).mean())\n",
    "print(\"accuracy: \", np.array(a).mean())\n",
    "print(\"recall macro: \", np.array(rmacro).mean())\n",
    "print(\"recall micro: \", np.array(rmicro).mean())\n",
    "print(\"recall binary macro: \", np.array(rbi).mean())\n",
    "print(\"f1: \", np.array(f).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXeDZQCe0xKB"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.savetxt(\"/content/drive/My Drive/german_gcn_fpr_mean.csv\", mean_fpr, delimiter=\",\")\n",
    "numpy.savetxt(\"/content/drive/My Drive/german_gcn_tpr_mean.csv\", mean_tpr, delimiter=\",\")\n",
    "\n",
    "df_mean_fpr = pd.DataFrame(mean_fpr)\n",
    "df_mean_fpr.to_csv('/content/drive/My Drive/df_mean_fpr_gcn.csv')\n",
    "df_mean_tpr = pd.DataFrame(mean_tpr)\n",
    "df_mean_tpr.to_csv('/content/drive/My Drive/df_mean_tpr_gcn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fo4Lz6x395A3"
   },
   "outputs": [],
   "source": [
    "''' viz = metrics.plot_roc_curve(model, X[test], predict_class,\n",
    "                             name='ROC fold {}'.format(i),\n",
    "                             alpha=0.3, lw=1, ax=ax)\n",
    "    interp_tpr = interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "    '''\n",
    "    '''ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "        label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Receiver operating characteristic example\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsgPKlfWuJQN"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/content/drive/My Drive/tp_spektral_german', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(tp, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjLk5kx-938B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jFAE_kwTKSbf"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/tn_spektral_german', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(tn, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bve-XrChKJDs"
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('/content/drive/My Drive/fp__spektral_german', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(fp, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dpeyfn_aJ7vu"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/fn__spektral_german', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(fn, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JysfYQzizDL9"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/precision__spektral_german', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(metrics_precision, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlJer7t-JoyB"
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('/content/drive/My Drive/accuracy__spektral_german', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(metrics_acc, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "in7_dwIhJCp0"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/F1_measure__spektral_german', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(metrics_f1, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jw07iYlQJZbR"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/recall__spektral', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(metrics_recall, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zk8cDZObuTlQ"
   },
   "outputs": [],
   "source": [
    "with open('tp', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    placesList = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "BqjqQQ-lufi0",
    "outputId": "a89cb031-31df-486b-c8fc-85e6125ea7fa"
   },
   "outputs": [],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HvtDoqFobTtc"
   },
   "outputs": [],
   "source": [
    "#micro-average classwise\n",
    "micro_precision_group_0 = (tp[0][0] + tp[1][0] + tp[2][0] + tp[3][0] + tp[4][0])/(tp[0][0] + tp[1][0] + tp[2][0] + tp[3][0] + \n",
    "                           tp[4][0] + fp[0][0] + fp[1][0] + fp[2][0] + fp[3][0] + fp[4][0])\n",
    "\n",
    "micro_precision_group_1 = (tp[0][1] + tp[1][1] + tp[2][1] + tp[3][1] + tp[4][1])/(tp[0][1] + tp[1][1] + tp[2][1] + tp[3][1] + \n",
    "                           tp[4][1] + fp[0][1] + fp[1][1] + fp[2][1] + fp[3][1] + fp[4][1])\n",
    "\n",
    "#micro_precision_group_2 = (tp[0][2] + tp[1][2] + tp[2][2] + tp[3][2] + tp[4][2])/(tp[0][2] + tp[1][2] + tp[2][2] + tp[3][2] + \n",
    "#                           tp[4][2] + fp[0][2] + fp[1][2] + fp[2][2] + fp[3][2] + fp[4][2])\n",
    "\n",
    "#micro_precision_group_3 = (tp[0][3] + tp[1][3] + tp[2][3] + tp[3][3] + tp[4][3])/(tp[0][3] + tp[1][3] + tp[2][3] + tp[3][3] + \n",
    "#                           tp[4][3] + fp[0][3] + fp[1][3] + fp[2][3] + fp[3][3] + fp[4][3])\n",
    "\n",
    "micro_recall_group_0 = (tp[0][0] + tp[1][0] + tp[2][0] + tp[3][0] + tp[4][0])/(tp[0][0] + tp[1][0] \n",
    "                        + tp[2][0] + tp[3][0] + tp[4][0] + fn[0][0] + fn[1][0] + fn[2][0] + fn[3][0] + fn[4][0])\n",
    "\n",
    "micro_recall_group_1 = (tp[0][1] + tp[1][1] + tp[2][1] + tp[3][1] + tp[4][1])/(tp[0][1] + tp[1][1] \n",
    "                        + tp[2][1] + tp[3][1] + tp[4][1] + fn[0][1] + fn[1][1] + fn[2][1] + fn[3][1] + fn[4][1])\n",
    "\n",
    "#micro_recall_group_2 = (tp[0][2] + tp[1][2] + tp[2][2] + tp[3][2] + tp[4][2])/(tp[0][2] + tp[1][2] \n",
    "#                        + tp[2][2] + tp[3][2] + tp[4][2] + fn[0][2] + fn[1][2] + fn[2][2] + fn[3][2] + fn[4][2])\n",
    "\n",
    "#micro_recall_group_3 = (tp[0][3] + tp[1][3] + tp[2][3] + tp[3][3] + tp[4][3])/(tp[0][3] + tp[1][3] \n",
    "#                        + tp[2][3] + tp[3][3] + tp[4][3] + fn[0][3] + fn[1][3] + fn[2][3] + fn[3][3] + fn[4][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "oyjn-0SQaXMM",
    "outputId": "ad5110b5-46d1-4119-8cfa-a1b8776d4651"
   },
   "outputs": [],
   "source": [
    "print(micro_recall_group_0)\n",
    "print(micro_recall_group_1)\n",
    "#print(micro_recall_group_2)\n",
    "#print(micro_recall_group_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "aaQRSW4OsCJB",
    "outputId": "3e588126-9c39-4619-faef-69684d5add51"
   },
   "outputs": [],
   "source": [
    "print(micro_precision_group_0)\n",
    "print(micro_precision_group_1)\n",
    "#print(micro_precision_group_2)\n",
    "#print(micro_precision_group_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Z8XS1PHxOjo"
   },
   "outputs": [],
   "source": [
    "micro_precision = []\n",
    "micro_precision.append(micro_precision_group_0)\n",
    "micro_precision.append(micro_precision_group_1)\n",
    "#micro_precision.append(micro_precision_group_2)\n",
    "#micro_precision.append(micro_precision_group_3)\n",
    "\n",
    "micro_recall = []\n",
    "micro_recall.append(micro_recall_group_0)\n",
    "micro_recall.append(micro_recall_group_1)\n",
    "#micro_recall.append(micro_recall_group_2)\n",
    "#micro_recall.append(micro_recall_group_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1KASKQccacPJ"
   },
   "outputs": [],
   "source": [
    " mirco_f1_group = []\n",
    "\n",
    "mirco_f1_group.append(2 * ((micro_precision_group_0 * micro_recall_group_0)/(micro_precision_group_0 \n",
    "                                                                                 + micro_recall_group_0)))\n",
    "mirco_f1_group.append(2 * ((micro_precision_group_1 * micro_recall_group_1)/(micro_precision_group_1 \n",
    "                                                                                 + micro_recall_group_1)))\n",
    "#mirco_f1_group.append(2 * ((micro_precision_group_2 * micro_recall_group_2)/(micro_precision_group_2 \n",
    "                                          #                                       + micro_recall_group_2)))\n",
    "#mirco_f1_group.append(2 * ((micro_precision_group_3 * micro_recall_group_3)/(micro_precision_group_3 \n",
    "                                           #                                      + micro_recall_group_3)))\n",
    "\n",
    "#f1_score = 2 * ((micro_precision * micro_recall)/(micro_precision + micro_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "q_4GI5vwsf6C",
    "outputId": "9caf148a-64c1-4c9a-c35a-a656a78ea0b8"
   },
   "outputs": [],
   "source": [
    "print(micro_precision)\n",
    "print(micro_recall)\n",
    "print(mirco_f1_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFw96xAksmvg"
   },
   "outputs": [],
   "source": [
    "# mean accuracy classwise\n",
    "mean_accuracy = []\n",
    "for i in range(0, classes):\n",
    "    a = []\n",
    "    for j in range(0, 5): #row\n",
    "        a.append(metrics_acc[j][i])\n",
    "        n = np.array(a)\n",
    "    mean_accuracy.append(n.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oEJ6K6wlsphl",
    "outputId": "c339c18f-9c96-4602-e0d3-988cbcf40973"
   },
   "outputs": [],
   "source": [
    "mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "R4gR8tkGsat1",
    "outputId": "1c6643d2-1f73-4c3a-b3c9-99f93107bcfa"
   },
   "outputs": [],
   "source": [
    "#macro-average classwise\n",
    "macro_precision_group_0 = (metrics_precision[0][0] + metrics_precision[1][0] + metrics_precision[2][0] + \n",
    "                           metrics_precision[3][0] + metrics_precision[4][0])/5\n",
    "macro_precision_group_1 = (metrics_precision[0][1] + metrics_precision[1][1] + metrics_precision[2][1] + \n",
    "                           metrics_precision[3][1] + metrics_precision[4][1])/5\n",
    "macro_precision_group_2 = (metrics_precision[0][2] + metrics_precision[1][2] + metrics_precision[2][2] + \n",
    "                           metrics_precision[3][2] + metrics_precision[4][2])/5\n",
    "macro_precision_group_3 = (metrics_precision[0][3] + metrics_precision[1][3] + metrics_precision[2][3] + \n",
    "                           metrics_precision[3][3] + metrics_precision[4][3])/5\n",
    "\n",
    "macro_recall_group_0 = (metrics_recall[0][0] + metrics_recall[1][0] + metrics_recall[2][0] + \n",
    "                           metrics_recall[3][0] + metrics_recall[4][0])/5\n",
    "macro_recall_group_1 = (metrics_recall[0][1] + metrics_recall[1][1] + metrics_recall[2][1] + \n",
    "                           metrics_recall[3][1] + metrics_recall[4][1])/5\n",
    "macro_recall_group_2 = (metrics_recall[0][2] + metrics_recall[1][2] + metrics_recall[2][2] + \n",
    "                           metrics_recall[3][2] + metrics_recall[4][2])/5\n",
    "macro_recall_group_3 = (metrics_recall[0][3] + metrics_recall[1][3] + metrics_recall[2][3] + \n",
    "                           metrics_recall[3][3] + metrics_recall[4][3])/5\n",
    "\n",
    "macro_f1_group_0 = 2 * ((macro_precision_group_0 * macro_recall_group_0)/(macro_precision_group_0 + macro_recall_group_0))\n",
    "\n",
    "macro_f1_group_1 = 2 * ((macro_precision_group_1 * macro_recall_group_1)/(macro_precision_group_1 + macro_recall_group_1))\n",
    "\n",
    "macro_f1_group_2 = 2 * ((macro_precision_group_2 * macro_recall_group_2)/(macro_precision_group_2 + macro_recall_group_2))\n",
    "\n",
    "macro_f1_group_3 = 2 * ((macro_precision_group_3 * macro_recall_group_3)/(macro_precision_group_3 + macro_recall_group_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "SsaKJZPrsj9V",
    "outputId": "393ee7ba-94d9-4c7a-8f2e-bcf8495bbc60"
   },
   "outputs": [],
   "source": [
    "macro_precision = []\n",
    "macro_precision.append(macro_precision_group_0)\n",
    "macro_precision.append(macro_precision_group_1)\n",
    "macro_precision.append(macro_precision_group_2)\n",
    "macro_precision.append(macro_precision_group_3)\n",
    "\n",
    "macro_recall = []\n",
    "macro_recall.append(macro_recall_group_0)\n",
    "macro_recall.append(macro_recall_group_0)\n",
    "macro_recall.append(macro_recall_group_0)\n",
    "macro_recall.append(macro_recall_group_0)\n",
    "\n",
    "marco_f1_group = []\n",
    "\n",
    "marco_f1_group.append(2 * ((macro_precision_group_0 * macro_recall_group_0)/(macro_precision_group_0 \n",
    "                                                                                 + macro_recall_group_0)))\n",
    "marco_f1_group.append(2 * ((macro_precision_group_1 * macro_recall_group_1)/(macro_precision_group_1 \n",
    "                                                                                 + macro_recall_group_1)))\n",
    "marco_f1_group.append(2 * ((macro_precision_group_2 * macro_recall_group_2)/(macro_precision_group_2 \n",
    "                                                                                 + macro_recall_group_2)))\n",
    "marco_f1_group.append(2 * ((macro_precision_group_3 * macro_recall_group_3)/(macro_precision_group_3 \n",
    "                                                                                 + macro_recall_group_3)))\n",
    "\n",
    "#f1_score = 2 * ((micro_precision * micro_recall)/(micro_precision + micro_recall))\n",
    "\n",
    "print(macro_precision)\n",
    "print(macro_recall)\n",
    "print(marco_f1_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "aKQhMRKFsrIn",
    "outputId": "3f96bceb-d75c-41b0-e4a1-a45730cdce2f"
   },
   "outputs": [],
   "source": [
    "metrics_acc # verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cem1r1Vcssu1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Charliehebdo_gcn_Copy1_spektral_german.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
